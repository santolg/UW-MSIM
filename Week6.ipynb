{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e4b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c2cdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12pgdhovmrktzm3i23es5d5junftft3f</td>\n",
       "      <td>lekanaVEVO1</td>\n",
       "      <td>2014-07-22T15:27:50</td>\n",
       "      <td>i love this so much. AND also I Generate Free ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13yx345uxepetggz04ci5rjcxeohzlrtf4</td>\n",
       "      <td>Pyunghee</td>\n",
       "      <td>2014-07-27T01:57:16</td>\n",
       "      <td>http://www.billboard.com/articles/columns/pop-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k</td>\n",
       "      <td>Erica Ross</td>\n",
       "      <td>2014-07-27T02:51:43</td>\n",
       "      <td>Hey guys! Please join me in my fight to help a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jcjuovxbwfr0ge04cev2ipsjdfdurwck</td>\n",
       "      <td>Aviel Haimov</td>\n",
       "      <td>2014-08-01T12:27:48</td>\n",
       "      <td>http://psnboss.com/?ref=2tGgp3pV6L this is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k</td>\n",
       "      <td>John Bello</td>\n",
       "      <td>2014-08-01T21:04:03</td>\n",
       "      <td>Hey everyone. Watch this trailer!!!!!!!!  http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID        AUTHOR                 DATE  \\\n",
       "0      z12pgdhovmrktzm3i23es5d5junftft3f   lekanaVEVO1  2014-07-22T15:27:50   \n",
       "1    z13yx345uxepetggz04ci5rjcxeohzlrtf4      Pyunghee  2014-07-27T01:57:16   \n",
       "2  z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k    Erica Ross  2014-07-27T02:51:43   \n",
       "3    z13jcjuovxbwfr0ge04cev2ipsjdfdurwck  Aviel Haimov  2014-08-01T12:27:48   \n",
       "4  z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k    John Bello  2014-08-01T21:04:03   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0  i love this so much. AND also I Generate Free ...      1  \n",
       "1  http://www.billboard.com/articles/columns/pop-...      1  \n",
       "2  Hey guys! Please join me in my fight to help a...      1  \n",
       "3  http://psnboss.com/?ref=2tGgp3pV6L this is the...      1  \n",
       "4  Hey everyone. Watch this trailer!!!!!!!!  http...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data: selecting KatyPerry, LMFAO, Eminem, Shakira\n",
    "\n",
    "# merging csv files\n",
    "df = pd.concat(\n",
    "    map(pd.read_csv, ['Youtube02-KatyPerry.csv', 'Youtube03-LMFAO.csv', 'Youtube04-Eminem.csv', 'Youtube05-Shakira.csv']), ignore_index=True)\n",
    "#preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e849c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/3586069163.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['CONTENT'] = df['CONTENT'].str.replace('[^\\w\\s]','')\n",
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/3586069163.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['CONTENT'] = df['CONTENT'].str.replace('\\d+', '')\n",
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/3586069163.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['CONTENT'] = df['CONTENT'].str.replace('\\s+', ' ')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/laurensantos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    830\n",
       "0    776\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean comment data\n",
    "\n",
    "#convert comments to string type\n",
    "df['CONTENT'] = df['CONTENT'].astype(str)\n",
    "#lower case all comments\n",
    "df['CONTENT'] = df['CONTENT'].str.lower()\n",
    "#remove punctuation\n",
    "df['CONTENT'] = df['CONTENT'].str.replace('[^\\w\\s]','')\n",
    "#remove numbers\n",
    "df['CONTENT'] = df['CONTENT'].str.replace('\\d+', '')\n",
    "#remove extra spaces\n",
    "df['CONTENT'] = df['CONTENT'].str.replace('\\s+', ' ')\n",
    "#include only English alphabet\n",
    "df[df['CONTENT'].map(lambda x: x.isascii())]\n",
    "#remove stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "df['CONTENT'] = df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "#how many of each class?\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052b9afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurensantos/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#transform data\n",
    "cv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", stop_words=None, ngram_range=(1,1), analyzer='word')\n",
    "dt_mat = cv.fit_transform(df.CONTENT)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_mat = tfidf_transformer.fit_transform(dt_mat)\n",
    "\n",
    "words = pd.DataFrame(dt_mat.todense(), index=df.index, columns=cv.get_feature_names())\n",
    "words['CLASS'] = df.CLASS\n",
    "#print(words)\n",
    "\n",
    "#there are 3416 unique words in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4ce5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8941908713692946\n",
      "[[201  18]\n",
      " [ 33 230]]\n"
     ]
    }
   ],
   "source": [
    "X = words.iloc[:, 0:3416]\n",
    "y = words.iloc[: , -1:]\n",
    "\n",
    "#train/test data using 70/30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "\n",
    "#using multinomial distribution; discrete counting of words\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d6cd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on remaining dataset \n",
    "psy_df = pd.read_csv('Youtube01-Psy.csv')\n",
    "\n",
    "#preview\n",
    "psy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2012c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/2101640157.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('[^\\w\\s]','')\n",
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/2101640157.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('\\d+', '')\n",
      "/var/folders/t6/96kvh0194vl8gsjz443_h2f80000gn/T/ipykernel_30562/2101640157.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('\\s+', ' ')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/laurensantos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    175\n",
       "0    175\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean comment data\n",
    "\n",
    "#convert comments to string type\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].astype(str)\n",
    "#lower case all comments\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].str.lower()\n",
    "#remove punctuation\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('[^\\w\\s]','')\n",
    "#remove numbers\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('\\d+', '')\n",
    "#remove extra spaces\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].str.replace('\\s+', ' ')\n",
    "#include only English alphabet\n",
    "psy_df[psy_df['CONTENT'].map(lambda x: x.isascii())]\n",
    "#remove stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "psy_df['CONTENT'] = psy_df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "#how many of each class?\n",
    "psy_df['CLASS'].value_counts()\n",
    "#there are 170 in each class; even split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f483f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurensantos/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#transform data\n",
    "cv2 = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", stop_words=None, ngram_range=(1,1), analyzer='word')\n",
    "dt_mat2 = cv2.fit_transform(psy_df.CONTENT)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_mat2 = tfidf_transformer.fit_transform(dt_mat2)\n",
    "\n",
    "words2 = pd.DataFrame(dt_mat2.todense(), index=psy_df.index, columns=cv2.get_feature_names())\n",
    "words2['CLASS'] = psy_df.CLASS\n",
    "#print(words2)\n",
    "#there are 1097 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68fce4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9914285714285714\n",
      "[[173   2]\n",
      " [  1 174]]\n"
     ]
    }
   ],
   "source": [
    "X = words2.iloc[:, 0:1097]\n",
    "y = words2.iloc[: , -1:]\n",
    "\n",
    "#using multinomial distribution; discrete counting of words\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X, y.values.ravel())\n",
    "\n",
    "y_pred = mnb.predict(X)\n",
    "\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6947c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
