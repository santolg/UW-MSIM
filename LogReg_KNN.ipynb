{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d41b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547e29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM 1\n",
    "#load data\n",
    "rating_df = pd.read_csv('Problem 1—quality.csv')\n",
    "#drop 1st column\n",
    "rating_df = rating_df.iloc[: , 1:]\n",
    "\n",
    "#preview data\n",
    "rating_df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d9761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words            0\n",
      "num_characters       0\n",
      "num_misspelled       0\n",
      "bin_end_qmark        0\n",
      "num_interrogative    0\n",
      "bin_start_small      0\n",
      "num_sentences        0\n",
      "num_punctuations     0\n",
      "label                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values\n",
    "print(rating_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60942de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating independent features\n",
    "X = rating_df.drop(['label'], axis = 1)\n",
    "#isolating class label\n",
    "y = rating_df['label']\n",
    "\n",
    "# normalize feature variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_features = X\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "#create train/test using 70% for training\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.40, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2feeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model\n",
    "logmodel= LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58dd6926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Classification report on test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.43      0.75      0.55         4\n",
      "           G       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.61      0.62      0.58        12\n",
      "weighted avg       0.68      0.58      0.59        12\n",
      "\n",
      "LR Accuracy on test data\n",
      "0.5833333333333334\n",
      "LR Confusion matrix of test data\n",
      "[[3 1]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "print('LR Classification report on test data')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('LR Accuracy on test data')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print('LR Confusion matrix of test data')\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1538e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression using num_mispelled and num_interrogative as independent features\n",
    "#isolating independent features\n",
    "X1 = rating_df[['num_misspelled', 'num_interrogative']]\n",
    "#isolating class label\n",
    "y1 = rating_df['label']\n",
    "\n",
    "# normalize feature variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X1_features = X1\n",
    "X1 = StandardScaler().fit_transform(X1)\n",
    "\n",
    "#create train/test using 70% for training\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split (X1, y1, test_size = 0.40, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "442f0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model\n",
    "logmodel= LogisticRegression()\n",
    "logmodel.fit(X1_train, y1_train)\n",
    "\n",
    "predictions1 = logmodel.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc6702e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Classification report on test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.27      0.75      0.40         4\n",
      "           G       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.14      0.38      0.20        12\n",
      "weighted avg       0.09      0.25      0.13        12\n",
      "\n",
      "LR Accuracy on test data\n",
      "0.25\n",
      "LR Confusion matrix of test data\n",
      "[[3 1]\n",
      " [8 0]]\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "print('LR Classification report on test data')\n",
    "print(classification_report(y1_test, predictions1, zero_division= 1))\n",
    "print('LR Accuracy on test data')\n",
    "print(accuracy_score(y1_test, predictions1))\n",
    "\n",
    "print('LR Confusion matrix of test data')\n",
    "print(confusion_matrix(y1_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2712e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression using num_words and num_punctuations as independent features\n",
    "#isolating independent features\n",
    "X2 = rating_df[['num_words', 'num_punctuations']]\n",
    "#isolating class label\n",
    "y2 = rating_df['label']\n",
    "\n",
    "# normalize feature variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X2_features = X2\n",
    "X2 = StandardScaler().fit_transform(X2)\n",
    "\n",
    "#create train/test using 70% for training\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split (X2, y2, test_size = 0.40, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19266921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model\n",
    "logmodel= LogisticRegression()\n",
    "logmodel.fit(X2_train, y2_train)\n",
    "\n",
    "predictions2 = logmodel.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8733c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Classification report on test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.40      1.00      0.57         4\n",
      "           G       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.70      0.62      0.49        12\n",
      "weighted avg       0.80      0.50      0.46        12\n",
      "\n",
      "LR Accuracy on test data\n",
      "0.5\n",
      "LR Confusion matrix of test data\n",
      "[[4 0]\n",
      " [6 2]]\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "print('LR Classification report on test data')\n",
    "print(classification_report(y2_test, predictions2))\n",
    "print('LR Accuracy on test data')\n",
    "print(accuracy_score(y2_test, predictions2))\n",
    "\n",
    "print('LR Confusion matrix of test data')\n",
    "print(confusion_matrix(y2_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50690557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "      <th>is_red</th>\n",
       "      <th>high_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality color  is_red  high_quality  \n",
       "0      9.4        5   red     1.0           0.0  \n",
       "1      9.8        5   red     1.0           0.0  \n",
       "2      9.8        5   red     1.0           0.0  \n",
       "3      9.8        6   red     1.0           0.0  \n",
       "4      9.4        5   red     1.0           0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROBLEM 2\n",
    "#load data\n",
    "wine_df = pd.read_csv('Problem 2—wine dataset.csv')\n",
    "\n",
    "#preview data\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5052105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "color                   0\n",
      "is_red                  0\n",
      "high_quality            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values\n",
    "print(wine_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3befe554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.000027\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           high_quality   No. Observations:                 6497\n",
      "Model:                          Logit   Df Residuals:                     6485\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Sat, 22 Jan 2022   Pseudo R-squ.:                  0.9999\n",
      "Time:                        17:01:11   Log-Likelihood:               -0.17665\n",
      "converged:                      False   LL-Null:                       -3219.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "fixed_acidity           1.4214      2.344      0.606      0.544      -3.173       6.016\n",
      "volatile_acidity       -5.4875     43.030     -0.128      0.899     -89.825      78.850\n",
      "citric_acid            -0.4000     26.848     -0.015      0.988     -53.022      52.222\n",
      "residual_sugar          0.0478      1.076      0.044      0.965      -2.061       2.157\n",
      "chlorides             -23.7857    226.446     -0.105      0.916    -467.612     420.041\n",
      "free_sulfur_dioxide     0.0524      0.212      0.248      0.804      -0.362       0.467\n",
      "density              -241.8300    268.213     -0.902      0.367    -767.518     283.858\n",
      "pH                     11.9428     27.538      0.434      0.665     -42.031      65.917\n",
      "sulphates              10.8261     17.938      0.604      0.546     -24.332      45.984\n",
      "alcohol                -0.5637      4.942     -0.114      0.909     -10.251       9.123\n",
      "quality                29.8661     31.813      0.939      0.348     -32.486      92.218\n",
      "is_red                 -0.6638      8.644     -0.077      0.939     -17.606      16.279\n",
      "=======================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.98 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurensantos/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#trial-and-error; good subset of features\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cols = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'is_red']\n",
    "\n",
    "X1 = wine_df[cols]\n",
    "y1 = wine_df['high_quality']\n",
    "\n",
    "logit_model=sm.Logit(y1,X1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "#variables with lowest p values (not including quality): fixed_acidity, density, sulphates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5072c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#isolating independent features, test 1\n",
    "X = wine_df[['fixed_acidity', 'density', 'sulphates']]\n",
    "#isolating class label\n",
    "y = wine_df['high_quality']\n",
    "\n",
    "\n",
    "# normalize feature variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_features = X\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "\n",
    "#create train/test using 70% for training\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.30, random_state = 2)\n",
    "\n",
    "#create KNN Classifier model\n",
    "knn = Kn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a2cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 10, accuracy is 0.838.\n",
      "Best k = 2.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#best accuracy parameter\n",
    "best_accuracy = 0\n",
    "#testing for k values 2 through 10\n",
    "for i in range(2, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_score = knn.score(X_train,y_train)\n",
    "#comparing accuracy of k scores\n",
    "    if train_score > best_accuracy:\n",
    "        best_accuracy = train_score\n",
    "        best_k = i\n",
    "\n",
    "print(f'For k = {i}, accuracy is {round(train_score,3)}.')\n",
    "print(f'Best k = {best_k}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6075fdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot k accuracies\n",
    "y = [0.908, 0.896, 0.867, 0.861, 0.854, 0.846, 0.841, 0.838, 0.838]\n",
    "x = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
